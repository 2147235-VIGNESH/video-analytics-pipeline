{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "import sqlite3\n",
        "import time"
      ],
      "metadata": {
        "id": "vU4XDtCn86RC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l--PR5ZC64LV",
        "outputId": "1758f2ed-79fc-4058-9ea0-fe85a04a2bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install opencv-python numpy json sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_config(filename):\n",
        "    with open(filename) as f:\n",
        "        config = json.load(f)\n",
        "    return config\n",
        "\n",
        "\n",
        "def capture_frames(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    frame_count = 0\n",
        "    frames_in_batch = []\n",
        "    current_batch_start_time = time.time()\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            frame_count += 1\n",
        "\n",
        "            # Process frame\n",
        "            process_frame(frame, frame_count, frames_in_batch, current_batch_start_time)\n",
        "\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    if frames_in_batch:\n",
        "        current_batch_id = generate_unique_id()\n",
        "        create_and_store_batch(frames_in_batch, current_batch_id)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "\n",
        "def process_frame(frame, frame_count, frames_in_batch, current_batch_start_time):\n",
        "    # Extract relevant information\n",
        "    camera_id = \"camera_1\"\n",
        "    frame_id = frame_count\n",
        "    geo_location = \"(40.7128,-74.0060)\"\n",
        "\n",
        "    # Save frame as JPEG image every second\n",
        "    if frame_count % 25 == 0:\n",
        "        image_path = f\"data/frame_{frame_id}.jpg\"\n",
        "        cv2.imwrite(image_path, frame)\n",
        "\n",
        "    # Create JSON object\n",
        "    frame_data = {\n",
        "        \"camera_id\": camera_id,\n",
        "        \"frame_id\": frame_id,\n",
        "        \"geo_location\": geo_location,\n",
        "        \"image_path\": image_path,\n",
        "    }\n",
        "\n",
        "    # Add frame to current batch\n",
        "    frames_in_batch.append(frame_data)\n",
        "\n",
        "    # Check if batch is full or duration is exceeded and create a new one if needed\n",
        "    current_time = time.time()\n",
        "    batch_duration = current_time - current_batch_start_time\n",
        "    if len(frames_in_batch) == config[\"batch_size\"] or batch_duration > config[\"duration\"]:\n",
        "        current_batch_id = generate_unique_id()\n",
        "        create_and_store_batch(frames_in_batch, current_batch_id)\n",
        "        frames_in_batch = []\n",
        "        current_batch_start_time = current_time\n",
        "\n",
        "\n",
        "def create_and_store_batch(frames, batch_id):\n",
        "    batch = create_batch(frames, batch_id)\n",
        "\n",
        "    # Connect to database\n",
        "    conn = sqlite3.connect(\"video_analytics.db\")\n",
        "\n",
        "    # Create tables if they don't exist\n",
        "    create_tables(conn)\n",
        "\n",
        "    # Insert batch information\n",
        "    cursor = conn.cursor()\n",
        "    sql = \"INSERT INTO batches (batch_id, starting_frame_id, ending_frame_id, timestamp) VALUES (?, ?, ?, ?)\"\n",
        "    cursor.execute(sql, (batch[\"batch_id\"], batch[\"starting_frame_id\"], batch[\"ending_frame_id\"], batch[\"timestamp\"]))\n",
        "    conn.commit()\n",
        "\n",
        "    # Close database connection\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def create_batch(frames, batch_id):\n",
        "    starting_frame_id = frames[0][\"frame_id\"]\n",
        "    ending_frame_id = frames[-1][\"frame_id\"]\n",
        "    timestamp = ... # Implement logic to retrieve timestamp\n",
        "    return {\n",
        "        \"batch_id\": batch_id,\n",
        "        \"starting_frame_id\": starting_frame_id,\n",
        "        \"ending_frame_id\": ending_frame_id,\n",
        "        \"timestamp\": timestamp,\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_unique_id():\n",
        "    # Implement logic to generate unique IDs for batches\n",
        "    ...\n",
        "\n",
        "\n",
        "def create_tables(conn):\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('''CREATE TABLE IF NOT EXISTS batches (\n",
        "        batch_id TEXT PRIMARY KEY,\n",
        "        starting_frame_id INTEGER,\n",
        "        ending_frame_id INTEGER,\n",
        "        timestamp DATETIME\n",
        "    )''')\n",
        "    conn.commit()\n",
        "\n",
        "\n",
        "# Run functions\n",
        "config = read_config(\"config.json\")\n",
        "capture_frames(\"data/video.mp4\")\n"
      ],
      "metadata": {
        "id": "g0H3oTq6-QFQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(filename=\"video_analytics.log\", level=logging.INFO)\n",
        "\n",
        "try:\n",
        "    # Capture frames\n",
        "    capture_frames(video_path)\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error during frame capture: {str(e)}\")\n",
        "\n",
        "try:\n",
        "    # Create and store batches\n",
        "    for frames_in_batch in batch_generator:\n",
        "        create_and_store_batch(frames_in_batch, generate_unique_id())\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error during batch creation/storage: {str(e)}\")\n",
        "\n",
        "finally:\n",
        "    # Close database connection\n",
        "    conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2jVckuo-z0e",
        "outputId": "864101da-0833-49e3-8ae1-01af2707906a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Error during batch creation/storage: name 'batch_generator' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "threads = []\n",
        "\n",
        "# Create and start threads for each camera stream\n",
        "for camera_id in config[\"camera_ids\"]:\n",
        "    thread = threading.Thread(target=capture_frames, args=(f\"data/{camera_id}.mp4\",))\n",
        "    thread.start()\n",
        "    threads.append(thread)\n",
        "\n",
        "# Wait for all threads to finish\n",
        "for thread in threads:\n",
        "    thread.join()"
      ],
      "metadata": {
        "id": "4sc6wWH_AsIb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_video(timestamp, duration):\n",
        "    # Connect to database\n",
        "    conn = sqlite3.connect(\"video_analytics.db\")\n",
        "\n",
        "    # Retrieve relevant batch information\n",
        "    cursor = conn.cursor()\n",
        "    sql = \"SELECT * FROM batches WHERE timestamp >= ? AND timestamp <= ?\"\n",
        "    cursor.execute(sql, (timestamp, timestamp + timedelta(seconds=duration)))\n",
        "    batches = cursor.fetchall()\n",
        "\n",
        "    # Create metadata for video retrieval\n",
        "    metadata = []\n",
        "    for batch in batches:\n",
        "        metadata.extend(get_frame_metadata(batch[\"batch_id\"]))\n",
        "\n",
        "    # Convert frames to video\n",
        "    video_path = convert_frames_to_video(metadata)\n",
        "\n",
        "    # Close database connection\n",
        "    conn.close()\n",
        "\n",
        "    return video_path\n",
        "\n",
        "\n",
        "def get_frame_metadata(batch_id):\n",
        "    # Read frames.json file\n",
        "    with open(\"data/frames.json\", \"r\") as f:\n",
        "        frames_data = json.load(f)\n",
        "\n",
        "    # Filter frames based on batch ID\n",
        "    frames_in_batch = [frame for frame in frames_data if frame[\"batch_id\"] == batch_id]\n",
        "\n",
        "    # Extract relevant information for each frame\n",
        "    metadata = []\n",
        "    for frame in frames_in_batch:\n",
        "        metadata.append({\n",
        "            \"camera_id\": frame[\"camera_id\"],\n",
        "            \"frame_id\": frame[\"frame_id\"],\n",
        "            \"image_path\": frame[\"image_path\"],\n",
        "        })\n",
        "\n",
        "    return metadata\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uPLVgNukAvCN"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OPkMqrEZAzU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}